{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from random import random\n",
    "from numpy import array\n",
    "from numpy import cumsum\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Embedding\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional, Concatenate, concatenate, Dropout, Input, Merge, TimeDistributed, Flatten\n",
    "from keras.layers import Convolution1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "from keras.models import Model\n",
    "import data_set\n",
    "from data_set import load_embeddings, fetch_data, fetch_embeddings\n",
    "from data_set import MAX_SEQUENCE_LENGTH_HEAD\n",
    "from data_set import MAX_SEQUENCE_LENGTH_BODY\n",
    "from data_set import EMBEDDING_DIM\n",
    "from data_set import VALIDATION_SPLIT\n",
    "from data_set import MAX_NUM_WORDS, embeddings_index, labels_index\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n",
      "All done\n"
     ]
    }
   ],
   "source": [
    "load_embeddings(BASE_DIR = '/Users/avinashaita/Desktop/DeepLearning/Keras Tutorial')\n",
    "(headlines, bodies_map, labels) = fetch_data(BASE_DIR = '/Users/avinashaita/Desktop/DeepLearning/Keras Tutorial/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing embedding matrix.\n",
      "All done\n"
     ]
    }
   ],
   "source": [
    "(data_head, data_body, embedding_layer_head, embedding_layer_body) = fetch_embeddings(headlines, bodies_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump((headlines, bodies_map, labels), open(\"train_file1.txt\", \"wb\"))\n",
    "pickle.dump((data_head, data_body, embedding_layer_head, embedding_layer_body), open(\"train_file2.txt\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(headlines, bodies_map, _) = pickle.load(open(\"train_file1.txt\", \"rb\"))\n",
    "(data_head, data_body, embedding_layer_head, embedding_layer_body) = pickle.load(open(\"train_file2.txt\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_title (InputLayer)        (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_body (InputLayer)         (None, 200)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 50, 50)       194000      input_title[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 200, 50)      1000000     input_body[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               multiple             8032        embedding_1[0][0]                \n",
      "                                                                 embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             multiple             0           conv1d_1[0][0]                   \n",
      "                                                                 conv1d_1[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  multiple             0           dropout_1[0][0]                  \n",
      "                                                                 dropout_1[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               multiple             10304       max_pooling1d_1[0][0]            \n",
      "                                                                 max_pooling1d_1[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             multiple             0           conv1d_4[0][0]                   \n",
      "                                                                 conv1d_4[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               multiple             30816       dropout_4[0][0]                  \n",
      "                                                                 dropout_4[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             multiple             0           conv1d_5[0][0]                   \n",
      "                                                                 conv1d_5[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 96)           0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 96)           0           dropout_5[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 192)          0           global_max_pooling1d_1[0][0]     \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          24704       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "out (Dense)                     (None, 4)            516         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,268,372\n",
      "Trainable params: 74,372\n",
      "Non-trainable params: 1,194,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Define model architecture\n",
    "\n",
    "#Declare Layers\n",
    "n_classes = 4\n",
    "emb_size = EMBEDDING_DIM\n",
    "n_hidden = 32\n",
    "width = 5\n",
    "\n",
    "#Conv\n",
    "conv_0  = Convolution1D(filters = n_hidden, kernel_size = width, activation='relu', padding='same')\n",
    "conv_1  = Convolution1D(filters = n_hidden, kernel_size = width, activation='relu', padding='same')\n",
    "conv_2  = Convolution1D(filters = 2*n_hidden, kernel_size = width, activation='relu', padding='same')\n",
    "conv_3  = Convolution1D(filters = 2*n_hidden, kernel_size = width, activation='relu', padding='same')\n",
    "conv_4  = Convolution1D(filters = 3*n_hidden, kernel_size = width, activation='relu', padding='same')\n",
    "\n",
    "#Dense\n",
    "dense_0 = Dense(n_hidden*4, activation='relu')\n",
    "dense_1 = Dense(n_hidden*4, activation='relu')\n",
    "dense_2 = Dense(n_hidden*4, activation='relu')\n",
    "dense_f = Dense(n_classes, activation='softmax', name='out')\n",
    "\n",
    "#Drop\n",
    "drop_0 = Dropout(0.25)\n",
    "drop_1 = Dropout(0.25)\n",
    "drop_2 = Dropout(0.25)\n",
    "drop_3 = Dropout(0.25)\n",
    "drop_4 = Dropout(0.25)\n",
    "\n",
    "#Pooling\n",
    "pool_0 = MaxPooling1D(pool_size=3, padding='same')\n",
    "pool_1 = MaxPooling1D(pool_size=3, padding='same')\n",
    "pool_2 = MaxPooling1D(pool_size=3, padding='same')\n",
    "\n",
    "#Input formats\n",
    "input_title   = Input(shape=(MAX_SEQUENCE_LENGTH_HEAD, ), dtype='int32', name='input_title')\n",
    "input_body   = Input(shape=(MAX_SEQUENCE_LENGTH_BODY, ), dtype='int32', name='input_body')\n",
    "\n",
    "#Create Layers - Title\n",
    "x = input_title\n",
    "x = embedding_layer_head(x)\n",
    "#x = dim_shuffle(x)\n",
    "x = conv_0(x)\n",
    "x = drop_0(x)\n",
    "x = pool_0(x)\n",
    "#x = conv_1(x)\n",
    "#x = drop_1(x)\n",
    "#x = pool_1(x)\n",
    "#x = conv_2(x)\n",
    "#x = drop_2(x)\n",
    "#x = pool_2(x)\n",
    "x = conv_3(x)\n",
    "x = drop_3(x)\n",
    "x = conv_4(x)\n",
    "x = drop_4(x)\n",
    "\n",
    "#Create Layers - Body\n",
    "y = input_body\n",
    "y = embedding_layer_body(y)\n",
    "#y = dim_shuffle(y)\n",
    "y = conv_0(y)\n",
    "y = drop_0(y)\n",
    "y = pool_0(y)\n",
    "#y = conv_1(y)\n",
    "#y = drop_1(y)\n",
    "#y = pool_1(y)\n",
    "#y = conv_2(y)\n",
    "#y = drop_2(y)\n",
    "#y = pool_2(y)\n",
    "y = conv_3(y)\n",
    "y = drop_3(y)\n",
    "y = conv_4(y)\n",
    "y = drop_4(y)\n",
    "\n",
    "#Max selection\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "y = GlobalMaxPooling1D()(y)\n",
    "\n",
    "#Concatenate Layers\n",
    "z = concatenate([x, y])\n",
    "#z = Merge(mode=\"concat\",name=\"concat_layer\")([x_new, y_new])\n",
    "\n",
    "#Create Dense layers\n",
    "z = dense_0(z)\n",
    "#z = dense_1(z)\n",
    "#z = dense_2(z)\n",
    "\n",
    "#Output layer\n",
    "out = dense_f(z)\n",
    "\n",
    "#Summary\n",
    "model = Model(inputs=[input_title, input_body], outputs=[out])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compile\n",
    "optimizer = Adam(lr=0.0002, beta_1=0.1, beta_2=0.001, epsilon=1e-08) # Optimization hyperparameters.\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss={'out':'categorical_crossentropy'},\n",
    "              loss_weights={'out': 1.0}, # These can be tuned.\n",
    "              metrics=['accuracy'])\n",
    "#lr=0.0002, b1=0.1, b2=0.001, e=1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "5000/5000 [==============================] - 13s 3ms/step - loss: 0.8499 - acc: 0.7184 - val_loss: 0.8996 - val_acc: 0.7630\n",
      "Epoch 2/5\n",
      "5000/5000 [==============================] - 14s 3ms/step - loss: 0.8307 - acc: 0.7194 - val_loss: 0.8526 - val_acc: 0.7630\n",
      "Epoch 3/5\n",
      "5000/5000 [==============================] - 14s 3ms/step - loss: 0.8140 - acc: 0.7212 - val_loss: 0.8899 - val_acc: 0.7640\n",
      "Epoch 4/5\n",
      "5000/5000 [==============================] - 13s 3ms/step - loss: 0.8027 - acc: 0.7226 - val_loss: 0.8792 - val_acc: 0.7660\n",
      "Epoch 5/5\n",
      "5000/5000 [==============================] - 13s 3ms/step - loss: 0.7971 - acc: 0.7232 - val_loss: 0.8165 - val_acc: 0.7660\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x117fcdcf8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train and Validate\n",
    "labels = to_categorical(np.asarray(list(zip(*headlines))[2]))\n",
    "model.fit([data_head[20000:25000], data_body[20000:25000]], labels[20000:25000],\n",
    "          validation_data=([data_head[1000:2000], data_body[1000:2000]], labels[1000:2000]),\n",
    "          batch_size=24, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3604,    0,    0,    3],\n",
       "       [ 375,    0,    0,    1],\n",
       "       [  99,    0,    0,    0],\n",
       "       [ 898,    0,    0,   20]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = model.predict([data_head[20000:25000], data_body[20000:25000]])\n",
    "\n",
    "lab = np.argmax(labels[20000:25000], axis = 1)\n",
    "pred = np.argmax(y_pred, axis = 1)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(lab, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
